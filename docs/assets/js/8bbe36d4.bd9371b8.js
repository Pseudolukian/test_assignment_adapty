"use strict";(self.webpackChunkadapty_docs=self.webpackChunkadapty_docs||[]).push([[5889],{13781:(e,t,i)=>{i.d(t,{A:()=>s});const s=i.p+"assets/images/c8399fb-CleanShot_2023-07-19_at_17.29.522x-faae321915ee0ef133e2abacfe7b751a.webp"},29446:(e,t,i)=>{i.d(t,{A:()=>s});const s=i.p+"assets/images/2bf4d9f-Area-312272ac07fab929a2e66c0c241594bb.gif"},36869:(e,t,i)=>{i.d(t,{A:()=>s});const s=i.p+"assets/images/e6b0674-Area-cb2bc96c3ee7f0275413f4e987ceff56.gif"},44968:(e,t,i)=>{i.d(t,{A:()=>s});const s=i.p+"assets/images/30c7b68-Area-6d06f57fd06c96a8c07691f8c74ebfb6.gif"},54312:(e,t,i)=>{i.r(t),i.d(t,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>n,metadata:()=>l,toc:()=>d});var s=i(74848),r=i(28453),a=i(34028);i(26393);const n={title:"A/B test results and metrics",description:"Analyze results and key metrics in Adapty to improve your app\u2019s subscription performance and user engagement.",metadataTitle:"Results and Metrics Analysis | Adapty Docs"},o=void 0,l={id:"results-and-metrics",title:"A/B test results and metrics",description:"Analyze results and key metrics in Adapty to improve your app\u2019s subscription performance and user engagement.",source:"@site/versioned_docs/version-3.0/results-and-metrics.md",sourceDirName:".",slug:"/results-and-metrics",permalink:"/docs/results-and-metrics",draft:!1,unlisted:!1,tags:[],version:"3.0",frontMatter:{title:"A/B test results and metrics",description:"Analyze results and key metrics in Adapty to improve your app\u2019s subscription performance and user engagement.",metadataTitle:"Results and Metrics Analysis | Adapty Docs"},sidebar:"tutorialSidebar",previous:{title:"Run and stop A/B test",permalink:"/docs/run_stop_ab_tests"},next:{title:"Maths behind the A/B tests",permalink:"/docs/maths-behind-it"}},c={},d=[{value:"A/B test results",id:"ab-test-results",level:3},{value:"A/B test metrics",id:"ab-test-metrics",level:2},{value:"Metrics controls",id:"metrics-controls",level:2},{value:"Profile install date filtration",id:"profile-install-date-filtration",level:3},{value:"Time ranges",id:"time-ranges",level:3},{value:"Available filters and grouping",id:"available-filters-and-grouping",level:3},{value:"Single metrics chart",id:"single-metrics-chart",level:2},{value:"A/B test summary",id:"ab-test-summary",level:2},{value:"Metrics definitions",id:"metrics-definitions",level:2},{value:"Revenue",id:"revenue",level:3},{value:"CR to purchases",id:"cr-to-purchases",level:3},{value:"CR trials",id:"cr-trials",level:3},{value:"Purchases",id:"purchases",level:3},{value:"Trials",id:"trials",level:3},{value:"Trials cancelled",id:"trials-cancelled",level:3},{value:"Refunds",id:"refunds",level:3},{value:"Views",id:"views",level:3},{value:"Unique views",id:"unique-views",level:3},{value:"Probability to be the best",id:"probability-to-be-the-best",level:3},{value:"ARPPU (Average revenue per paying user)",id:"arppu-average-revenue-per-paying-user",level:3},{value:"ARPAS (Average revenue per active subscriber)",id:"arpas-average-revenue-per-active-subscriber",level:3},{value:"Proceeds",id:"proceeds",level:3},{value:"Unique subscribers",id:"unique-subscribers",level:3},{value:"Unique paid subscribers",id:"unique-paid-subscribers",level:3},{value:"Refund rate",id:"refund-rate",level:3},{value:"Unique CR purchases",id:"unique-cr-purchases",level:3},{value:"Unique CR trials",id:"unique-cr-trials",level:3}];function h(e){const t={a:"a",br:"br",h2:"h2",h3:"h3",li:"li",p:"p",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsxs)(t.p,{children:["Discover important data and insights from our ",(0,s.jsx)(t.a,{href:"ab-tests",children:"A/B tests"}),", comparing different paywalls to see how they affect user behavior, engagement, and conversion rates. By looking at the metrics and results here, you can make smart choices and improve your app's performance. Dive into the data to find actionable insights and enhance your app's success."]}),"\n",(0,s.jsx)(t.h3,{id:"ab-test-results",children:"A/B test results"}),"\n",(0,s.jsx)(t.p,{children:"Here are three metrics that Adapty provides for A/B test results:"}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)("img",{src:i(13781).A,style:{border:"1px solid #727272",width:"700px",display:"block",margin:"0 auto"}})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Revenue"}),": This metric shows the total amount of money generated in USD from purchases and renewals, minus any refunds given to users. It includes both the initial purchase and any follow-up subscription renewals. Revenue helps you understand how each A/B test variant is performing financially and figure out which one brings in the most money."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Probability to be best"}),": Adapty utilizes a robust mathematical analysis framework to analyze A/B test results and provides a metric called Probability to be best. This metric assesses the likelihood that a particular variant is the best-performing option (in terms of its long-term revenue) among all the variants tested. The metric is expressed as a percentage value ranging from 1% to 100%. For detailed information on how Adapty calculates this metric, please refer to the ",(0,s.jsx)(t.a,{href:"maths-behind-it",children:"documentation."}),"The best performing option, determined by Revenue per 1K user, is highlighted in green and automatically selected as the default choice."]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Revenue per 1K users:"})," The revenue per 1K users metric calculates the average revenue generated per 1,000 users for each A/B test variant. This metric helps you understand the revenue efficiency of your variants, regardless of the total number of users. It allows you to compare the performance of different variants on a standardized scale and make informed decisions based on revenue generation efficiency."]}),"\n",(0,s.jsx)(t.p,{children:"**Prediction intervals for revenue 1K users: **The revenue per 1K users metric also includes prediction intervals. These prediction intervals represent the range within which the true revenue per 1,000 users for a given variant is predicted to fall based on the available data and statistical analysis."}),"\n",(0,s.jsx)(t.p,{children:"In the context of A/B testing, when analyzing the revenue generated by different variants, we calculate the average revenue per 1,000 users for each variant. Since revenue can vary among users, the prediction intervals provide a clear indication of the plausible values for the revenue per 1,000 users, taking into account the variability and uncertainty associated with the prediction process."}),"\n",(0,s.jsx)(t.p,{children:"By incorporating prediction intervals into the revenue per 1K users metric, Adapty enables you to assess the revenue efficiency of your A/B test variants while considering the range of potential revenue outcomes. This information helps you make data-driven decisions and optimize your subscription strategy effectively, by taking into account the uncertainty in the prediction process and the plausible values for revenue per 1,000 users."}),"\n",(0,s.jsx)(t.p,{children:"By analyzing these metrics provided by Adapty, you can gain insights into the financial performance, statistical significance, and revenue efficiency of your A/B test variants, enabling you to make data-driven decisions and optimize your subscription strategy effectively."}),"\n",(0,s.jsx)(t.h2,{id:"ab-test-metrics",children:"A/B test metrics"}),"\n",(0,s.jsx)(t.p,{children:"Adapty provides a comprehensive set of metrics to help you effectively measure the performance of your A/B test conducted on your paywall variations. These metrics are continuously updated in real-time, except for views, which are updated periodically. Understanding these metrics will help you assess the effectiveness of different variations and make data-driven decisions to optimize your paywall strategy."}),"\n",(0,s.jsx)(t.p,{children:"A/B test metrics are available on the A/B test list, where you can gain an overview of the performance of all your A/B tests. This comprehensive view offers aggregated metrics for each test variation, enabling you to compare their performance and identify significant differences. For a more detailed analysis of each A/B test, you can access the A/B Test detail metrics. This section provides in-depth metrics specific to the selected A/B test, allowing you to delve into the performance of individual variations."}),"\n",(0,s.jsx)(t.p,{children:"All metrics, except for views, are attributed to the product within the paywall."}),"\n",(0,s.jsx)(t.h2,{id:"metrics-controls",children:"Metrics controls"}),"\n",(0,s.jsx)(t.p,{children:"The system displays the metrics based on the selected time period and organizes them according to the left-side column parameter with three levels of indentation."}),"\n",(0,s.jsx)(t.h3,{id:"profile-install-date-filtration",children:"Profile install date filtration"}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)("img",{src:i(29446).A,style:{border:"1px solid #727272",width:"700px",display:"block",margin:"0 auto"}})}),"\n",(0,s.jsx)(t.p,{children:"The Filter metrics by install date checkbox enables the filtering of metrics based on the profile install date, instead of the default filters that use trial/purchase date for transactions or view date for paywall views. By selecting this checkbox, you can focus on measuring user acquisition performance for a specific period by aligning metrics with the profile install date. This option is useful for customizing the metrics analysis according to your specific needs."}),"\n",(0,s.jsx)(t.h3,{id:"time-ranges",children:"Time ranges"}),"\n",(0,s.jsx)(t.p,{children:"You can choose from a range of time periods to analyze metrics data, allowing you to focus on specific durations such as days, weeks, months, or custom date ranges."}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)("img",{src:i(95847).A,style:{border:"1px solid #727272",width:"700px",display:"block",margin:"0 auto"}})}),"\n",(0,s.jsx)(t.h3,{id:"available-filters-and-grouping",children:"Available filters and grouping"}),"\n",(0,s.jsx)(t.p,{children:"Adapty offers powerful tools for filtering and customizing metrics analysis to suit your needs. With Adapty's metrics page, you have access to various time ranges, grouping options, and filtering possibilities."}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"\u2705 Filter by: Audience, country, paywall, paywall state, paywall group, placement, country, store, product, and product store."}),"\n",(0,s.jsx)(t.li,{children:"\u2705 Group by: Product and store."}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:["You can find more information about the available controls, filters, grouping options, and how to use them for paywall analytics in ",(0,s.jsx)(t.a,{href:"controls-filters-grouping-compare-proceeds",children:"this documentation."})]}),"\n",(0,s.jsx)(t.h2,{id:"single-metrics-chart",children:"Single metrics chart"}),"\n",(0,s.jsx)(t.p,{children:"One of the key components of the paywall metrics page is the chart section, which visually represents the selected metrics and facilitates easy analysis."}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)("img",{src:i(36869).A,style:{border:"1px solid #727272",width:"700px",display:"block",margin:"0 auto"}})}),"\n",(0,s.jsx)(t.p,{children:"The chart section on the A/B test metrics page includes a horizontal bar chart that visually represents the chosen metric values. Each bar in the chart corresponds to a metric value and is proportional in size, making it easy to understand the data at a glance. The horizontal line indicates the timeframe being analyzed, and the vertical column displays the numeric values of the metrics. The total value of all the metric values is displayed next to the chart."}),"\n",(0,s.jsx)(t.p,{children:"Additionally, clicking on the arrow icon in the top right corner of the chart section expands the view, displaying the selected metrics on the full line of the chart."}),"\n",(0,s.jsx)(t.h2,{id:"ab-test-summary",children:"A/B test summary"}),"\n",(0,s.jsx)(t.p,{children:"Next to the single metrics chart, the A/B test details summary section is displayed, which includes information about the state, duration, placements, and other related details about the  A/B test."}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)("img",{src:i(81123).A,style:{border:"1px solid #727272",width:"700px",display:"block",margin:"0 auto"}})}),"\n",(0,s.jsx)(t.h2,{id:"metrics-definitions",children:"Metrics definitions"}),"\n",(0,s.jsx)(t.p,{children:"Here are the key metrics that are available for the A/B tests:"}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)("img",{src:i(44968).A,style:{border:"1px solid #727272",width:"700px",display:"block",margin:"0 auto"}})}),"\n",(0,s.jsx)(t.h3,{id:"revenue",children:"Revenue"}),"\n",(0,s.jsx)(t.p,{children:"Revenue represents the total amount of money generated in USD from purchases and renewals resulting from the A/B test. It includes the initial purchase and subsequent subscription renewals. The revenue metric is calculated before deducting the App Store or Play Store commission."}),"\n",(0,s.jsx)(t.h3,{id:"cr-to-purchases",children:"CR to purchases"}),"\n",(0,s.jsx)(t.p,{children:"The conversion rate to purchases measures the effectiveness of your A/B test in converting views into actual purchases. It is calculated by dividing the number of purchases by the number of views. For example, if you had 10 purchases and 100 views, the conversion rate to purchases would be 10%."}),"\n",(0,s.jsx)(t.h3,{id:"cr-trials",children:"CR trials"}),"\n",(0,s.jsx)(t.p,{children:"The conversion rate (CR) to trials is the number of trials started from A/B test divided by the number of views. Conversion rate to trials measures the effectiveness of your A/B test in converting views into trial activations. It is calculated by dividing the number of trials started by the number of views."}),"\n",(0,s.jsx)(t.h3,{id:"purchases",children:"Purchases"}),"\n",(0,s.jsx)(t.p,{children:"The purchases metric represents the total number of transactions made within the paywall resulting from the A/B test. It includes the following types of purchases:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"New purchases made on the paywall."}),"\n",(0,s.jsxs)(t.li,{children:["Trial conversions of trials that were activated on the paywall.",(0,s.jsx)(t.br,{}),"\n","Downgrades, upgrades, and cross-grades of subscriptions on the paywall."]}),"\n",(0,s.jsx)(t.li,{children:"Subscription restores on the paywall (e.g. when a subscription is expired without auto-renewal and is subsequently restored)."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"Please note that renewals are not included in the purchases metric."}),"\n",(0,s.jsx)(t.h3,{id:"trials",children:"Trials"}),"\n",(0,s.jsx)(t.p,{children:"The trials metric indicates the total number of activated trials resulting from the A/B test."}),"\n",(0,s.jsx)(t.h3,{id:"trials-cancelled",children:"Trials cancelled"}),"\n",(0,s.jsx)(t.p,{children:"The trials canceled metric represents the number of trials in which auto-renewal has been switched off. This occurs when users manually unsubscribe from the trial."}),"\n",(0,s.jsx)(t.h3,{id:"refunds",children:"Refunds"}),"\n",(0,s.jsx)(t.p,{children:"Refunds for the A/B test represent the number of refunded purchases and subscriptions specifically related to the tested paywall variations."}),"\n",(0,s.jsx)(t.h3,{id:"views",children:"Views"}),"\n",(0,s.jsx)(t.p,{children:"Views are the number of views of the paywalls that the A/B test consits of. If the user visits the paywalls two times, this will be counted as two visits."}),"\n",(0,s.jsx)(t.h3,{id:"unique-views",children:"Unique views"}),"\n",(0,s.jsx)(t.p,{children:"Unique views are the number of unique views of the paywall. If the user visits the paywall two times, this will be counted as one unique view."}),"\n",(0,s.jsx)(t.h3,{id:"probability-to-be-the-best",children:"Probability to be the best"}),"\n",(0,s.jsx)(t.p,{children:"The Probability to be the best metric quantifies the likelihood that a specific paywall variant within an A/B test is the top-performing option among all the tested paywalls. It provides a numerical probability indicating the relative performance of each paywall. The metric is expressed as a percentage value ranging from 1% to 100%."}),"\n",(0,s.jsx)(t.h3,{id:"arppu-average-revenue-per-paying-user",children:"ARPPU (Average revenue per paying user)"}),"\n",(0,s.jsx)(t.p,{children:"ARPPU stands for Average Revenue Per Paying User resulting from the A/B test. It is calculated as the total revenue divided by the number of unique paying users. For example, if you have generated $15,000 in revenue from 1,000 paying users, the ARPPU would be $15."}),"\n",(0,s.jsx)(t.h3,{id:"arpas-average-revenue-per-active-subscriber",children:"ARPAS (Average revenue per active subscriber)"}),"\n",(0,s.jsx)(t.p,{children:"ARPAS is a metric that allows you to measure the average revenue generated per active subscriber from running the A/B test. It is calculated by dividing the total revenue by the number of subscribers who have activated a trial or subscription. For example, if the total revenue is $5,000 and you have 1,000 subscribers, the ARPAS would be $5. This metric helps assess the average monetization potential per subscriber."}),"\n",(0,s.jsx)(t.h3,{id:"proceeds",children:"Proceeds"}),"\n",(0,s.jsxs)(t.p,{children:["The proceeds metric for the A/B test represents the actual amount of money received by the app owner in USD from purchases and renewals after deducting the applicable App Store / Play Store commission. It reflects the net revenue specifically associated with the paywall variations tested in the A/B test, contributing directly to the app's earnings. For more information on how proceeds are calculated, you can refer to the Adapty ",(0,s.jsx)(t.a,{href:"analytics-cohorts#revenue-vs-proceeds",children:"documentation."})]}),"\n",(0,s.jsx)(t.h3,{id:"unique-subscribers",children:"Unique subscribers"}),"\n",(0,s.jsx)(t.p,{children:"The unique subscribers metric represents the count of distinct individuals who has subscribed or activated a trial through the paywall variations in the A/B test. It considers each subscriber only once, irrespective of the number of subscriptions or trials they initiate."}),"\n",(0,s.jsx)(t.h3,{id:"unique-paid-subscribers",children:"Unique paid subscribers"}),"\n",(0,s.jsx)(t.p,{children:"The unique paid subscribers metric represents the number of unique individuals who have successfully completed a purchase and become paying subscribers through the paywall variations in the A/B test."}),"\n",(0,s.jsx)(t.h3,{id:"refund-rate",children:"Refund rate"}),"\n",(0,s.jsx)(t.p,{children:"The refund rate for the A/B test is calculated by dividing the number of refunds specifically associated with the paywall variations in the test by the number of first-time purchases (renewals are excluded). For instance, if there are 5 refunds and 1000 first-time purchases, the refund rate would be 0.5%."}),"\n",(0,s.jsx)(t.h3,{id:"unique-cr-purchases",children:"Unique CR purchases"}),"\n",(0,s.jsx)(t.p,{children:"The unique conversion rate to purchases for the A/B test is calculated by dividing the number of purchases specifically associated with the paywall variations in the test by the number of unique views. For example, if there are 10 purchases and 100 unique views, the unique conversion rate to purchases would be 10%."}),"\n",(0,s.jsx)(t.h3,{id:"unique-cr-trials",children:"Unique CR trials"}),"\n",(0,s.jsx)(t.p,{children:"The unique conversion rate to trials for the A/B test is calculated by dividing the number of trials started specifically associated with the paywall variations in the test by the number of unique views. For example, if there are 30 trials started and 100 unique views, the unique conversion rate to trials would be 30%."})]})}function u(e={}){const{wrapper:t}={...(0,r.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}},81123:(e,t,i)=>{i.d(t,{A:()=>s});const s=i.p+"assets/images/90fa3f5-Area-2bc2ea43f19cd95e6e4bfd29d7c47425.gif"},95847:(e,t,i)=>{i.d(t,{A:()=>s});const s=i.p+"assets/images/7878542-CleanShot_2023-07-19_at_17.39.052x-3dd88857bb0794982f25f59417f766ce.webp"}}]);